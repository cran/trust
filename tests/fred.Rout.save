
R Under development (unstable) (2015-06-30 r68608) -- "Unsuffered Consequences"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
>  library(trust)
> 
>  options(digits = 3)
> 
>  ##### four-way contingency table with all two-way interactions
> 
>  d <- c(3, 4, 5, 6)
>  n <- 1000
> 
>  ##### model matrix
>  m <- NULL
>  for (i in 1:d[1]) {
+      for (j in 1:d[2]) {
+          mfoo <- array(0, dim = d)
+          mfoo[i, j, , ] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  for (i in 1:d[1]) {
+      for (j in 1:d[3]) {
+          mfoo <- array(0, dim = d)
+          mfoo[i, , j, ] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  for (i in 1:d[1]) {
+      for (j in 1:d[4]) {
+          mfoo <- array(0, dim = d)
+          mfoo[i, , , j] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  for (i in 1:d[2]) {
+      for (j in 1:d[3]) {
+          mfoo <- array(0, dim = d)
+          mfoo[ , i, j, ] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  for (i in 1:d[2]) {
+      for (j in 1:d[4]) {
+          mfoo <- array(0, dim = d)
+          mfoo[ , i, , j] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  for (i in 1:d[3]) {
+      for (j in 1:d[4]) {
+          mfoo <- array(0, dim = d)
+          mfoo[ , , i, j] <- 1
+          mfoo <- as.vector(mfoo)
+          m <- cbind(m, mfoo)
+      }
+  }
>  dimnames(m) <- NULL
>  foo <- qr(m)
>  m <- m[ , foo$pivot[seq(1, foo$rank)]]
> 
>  ##### true parameter value
>  set.seed(42)
>  theta.true <- 0.25 * rnorm(ncol(m))
>  theta.true <- round(theta.true, 5)
> 
>  ##### simulate data
>  eta <- as.numeric(m %*% theta.true)
>  p <- exp(eta)
>  p <- p / sum(p)
>  x <- sample(nrow(m), n, replace = TRUE, prob = p)
>  x <- tabulate(x, nbins = nrow(m))
> 
>  ##### save data
>  iffy <- try(read.table("fred.txt"), silent = TRUE)
>  if (inherits(iffy, "try-error")) {
+      data <- data.frame(x = x, m = m)
+      write.table(data, file = "fred.txt", row.names = FALSE)
+  }
>  data <- read.table(file = "fred.txt", header = TRUE)
>  x <- data$x
>  data$x <- NULL
>  m <- as.matrix(data)
>  dimnames(m) <- NULL
> 
>  ##### log likelihood
>  objfun <- function(theta) {
+      eta <- as.numeric(m %*% theta)
+      p <- exp(eta)
+      f <- sum(x * eta - p)
+      g <- as.numeric(t(x - p) %*% m)
+      B <- sweep(- m, 1, p, "*")
+      B <- t(m) %*% B
+      list(value = f, gradient = g, hessian = B)
+  }
> 
>  ##### check it
>  sally <- objfun(theta.true)
>  epsilon <- 1e-8
>  mygrad <- double(length(theta.true))
>  for (i in 1:length(mygrad)) {
+      theta.eps <- theta.true
+      theta.eps[i] <- theta.true[i] + epsilon
+      sally.eps <- objfun(theta.eps)
+      mygrad[i] <- (sally.eps$value - sally$value) / epsilon
+  }
>  all.equal(sally$gradient, mygrad, tolerance = length(mygrad) * epsilon)
[1] TRUE
>  myhess <- matrix(NA, length(theta.true), length(theta.true))
>  for (i in 1:length(mygrad)) {
+      theta.eps <- theta.true
+      theta.eps[i] <- theta.true[i] + epsilon
+      sally.eps <- objfun(theta.eps)
+      myhess[i, ] <- (sally.eps$gradient - sally$gradient) / epsilon
+  }
>  all.equal(sally$hessian, myhess, tolerance = length(mygrad) * epsilon)
[1] TRUE
> 
>  fred <- trust(objfun, theta.true, 1, sqrt(ncol(m)), minimize = FALSE)
> 
>  fran <- glm.fit(m, x, family = poisson(), intercept = FALSE)
> 
>  all.equal(fran$coefficients, fred$argument)
[1] TRUE
> 
>  fred <- trust(objfun, rep(0, length(theta.true)), 1, sqrt(ncol(m)),
+      minimize = FALSE, blather = TRUE)
>  fred$converged
[1] TRUE
>  ceiling(log10(max(abs(fred$gradient))))
[1] -13
>  length(fred$r)
[1] 7
>  data.frame(type = fred$steptype, rho = fred$rho, change = fred$preddiff,
+      accept = fred$accept, r = fred$r)
       type   rho   change accept r
1 easy-easy 0.967 3.31e+02   TRUE 1
2 easy-easy 0.717 2.59e+02   TRUE 2
3 easy-easy 1.032 4.73e+01   TRUE 2
4    Newton 0.994 4.46e+00   TRUE 4
5    Newton 1.006 2.82e-02   TRUE 4
6    Newton 1.000 2.80e-06   TRUE 4
7    Newton 0.891 6.38e-14   TRUE 4
>  (fred$stepnorm / fred$r)[fred$accept & fred$steptype != "Newton"]
[1] 1 1 1
> 
> 
>  fred <- trust(objfun, rep(-5, length(theta.true)), 1, sqrt(ncol(m)),
+      minimize = FALSE, blather = TRUE)
>  fred$converged
[1] TRUE
>  ceiling(log10(max(abs(fred$gradient))))
[1] -13
>  length(fred$r)
[1] 16
>  data.frame(type = fred$steptype, rho = fred$rho, change = fred$preddiff,
+      accept = fred$accept, r = fred$r)
        type    rho   change accept    r
1  easy-easy  1.000 5.43e+02   TRUE 1.00
2  easy-easy  1.000 1.09e+03   TRUE 2.00
3  easy-easy  1.000 2.17e+03   TRUE 4.00
4  easy-easy  1.000 4.35e+03   TRUE 8.00
5  easy-easy  0.999 5.04e+03   TRUE 9.27
6  easy-easy  0.974 5.00e+03   TRUE 9.27
7  easy-easy  0.601 3.85e+03   TRUE 9.27
8  easy-easy  0.818 2.21e+03   TRUE 9.27
9  easy-easy -1.516 6.53e+02  FALSE 9.27
10 easy-easy  1.135 4.57e+02   TRUE 2.32
11 easy-easy  0.937 2.33e+02   TRUE 4.64
12    Newton  1.136 3.93e+01   TRUE 9.27
13    Newton  1.060 2.69e+00   TRUE 9.27
14    Newton  1.008 2.67e-02   TRUE 9.27
15    Newton  1.000 3.94e-06   TRUE 9.27
16    Newton  1.029 1.10e-13   TRUE 9.27
>  (fred$stepnorm / fred$r)[fred$accept & fred$steptype != "Newton"]
 [1] 1 1 1 1 1 1 1 1 1 1
> 
> 
> proc.time()
   user  system elapsed 
  1.876   0.076   1.946 
